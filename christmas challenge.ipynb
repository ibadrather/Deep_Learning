{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget --header=\"Host: uni-siegen.sciebo.de\" --header=\"User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/79.0.3945.130 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\" --header=\"Accept-Language: en-US,en;q=0.9\" --header=\"Cookie: oc9054b00818=5hkfi6da5ltfcnam506sgfvd57; oc_sessionPassphrase=GOASmDMbJjDN4wwMyum3hupHthVU83lPvTNs84iPZuLMGU3tbGXcXpRdU%2BGu7S%2BoLfryp973Nf2jXceRyeoq5%2BN%2F%2BTwsPPvW8IH9Imgdx7bbBAkOzxjuEQ0I9kYmSqVZ\" --header=\"Connection: keep-alive\" \"https://uni-siegen.sciebo.de/s/6L5PDytJVXsbBOG/download?path=%2F&files=train&downloadStartSecret=o3z466xn2p\" -O \"train.tar\" -c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget wget --header=\"Host: uni-siegen.sciebo.de\" --header=\"User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/79.0.3945.130 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\" --header=\"Accept-Language: en-US,en;q=0.9\" --header=\"Cookie: oc9054b00818=5hkfi6da5ltfcnam506sgfvd57; oc_sessionPassphrase=GOASmDMbJjDN4wwMyum3hupHthVU83lPvTNs84iPZuLMGU3tbGXcXpRdU%2BGu7S%2BoLfryp973Nf2jXceRyeoq5%2BN%2F%2BTwsPPvW8IH9Imgdx7bbBAkOzxjuEQ0I9kYmSqVZ\" --header=\"Connection: keep-alive\" \"https://uni-siegen.sciebo.de/s/6L5PDytJVXsbBOG/download?path=%2F&files=val&downloadStartSecret=eyag1di9k4w\" -O \"val.tar\" -c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install patool\n",
    "# import patoolib\n",
    "# import os\n",
    "# patoolib.extract_archive(\"train.tar\")\n",
    "# patoolib.extract_archive(\"val.tar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The libraries you need for plotting images\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_dir = '/resources/data/train_christmas/christmas_cookies/0.png'\n",
    "#train_dir = '/resources/data/train_data_keras/5/0.jpeg'\n",
    "#name = '/0.jpeg'\n",
    "#Input = train_dir + name\n",
    "img = Image.open(train_dir)\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import Keras Modules\n",
    "\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Non-Keras Modules\n",
    "\n",
    "import os\n",
    "from matplotlib.pyplot import imshow\n",
    "import matplotlib.pylab as plt\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_SIZE = (224, 224)\n",
    "BATCH_SIZE = 50\n",
    "CLASSES = ['christmas_cookies', 'christmas_presents', 'christmas_tree', 'fireworks', 'penguin', 'reindeer', 'santa','snowman']\n",
    "RANDOM_SEED = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the train dataset folder and store it in train_data_dir\n",
    "train_data_dir = '/resources/data/train_christmas/'"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Generate training image dataset\n",
    "\n",
    "train_generator = ImageDataGenerator().flow_from_directory(train_data_dir\n",
    "                                                           , target_size=TARGET_SIZE\n",
    "                                                           , batch_size=BATCH_SIZE\n",
    "                                                           , classes=CLASSES\n",
    "                                                           , seed=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the validation dataset folder and store it in validation_data_dir\n",
    "\n",
    "validation_data_dir = '/resources/data/validation_christmas/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 358 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_generator = ImageDataGenerator().flow_from_directory(validation_data_dir\n",
    "                                                           , target_size=TARGET_SIZE\n",
    "                                                           , batch_size=BATCH_SIZE\n",
    "                                                           , classes=CLASSES\n",
    "                                                           , seed=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "BATCH_SIZE = train_generator.batch_size\n",
    "for i in range(BATCH_SIZE):\n",
    "    img = train_generator.next()[0][i]\n",
    "    img = img.astype(np.uint8)\n",
    "    plt.figure(i+1)\n",
    "    plt.imshow(img)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "BATCH_SIZE = validation_generator.batch_size\n",
    "for i in range(BATCH_SIZE):\n",
    "    img = train_generator.next()[0][i]\n",
    "    img = img.astype(np.uint8)\n",
    "    plt.figure(i+1)\n",
    "    plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense\n",
    "# from keras.preprocessing.image import ImageDataGenerator\n",
    "# from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers.convolutional import Conv2D # to add convolutional layers\n",
    "from keras.layers.convolutional import MaxPooling2D # to add pooling layers\n",
    "from keras.layers import Flatten # to flatten data for fully connected layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-Keras Modules\n",
    "\n",
    "import os\n",
    "from imageio import imread\n",
    "from matplotlib.pyplot import imshow\n",
    "import matplotlib.pylab as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import random"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def convolutional_model():\n",
    "    \n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(16, (3, 3), strides=(1, 1), activation='relu', input_shape=(224,224)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(CLASSES, activation='softmax'))\n",
    "    \n",
    "    # compile model\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy',  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
      "553467904/553467096 [==============================] - 12s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Use VGG16 to train the model and print out the last validation accuracy.\n",
    "\n",
    "# Type your code here\n",
    "\n",
    "base1 = VGG16(weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for layer in base1.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 8)                 32776     \n",
      "=================================================================\n",
      "Total params: 134,293,320\n",
      "Trainable params: 32,776\n",
      "Non-trainable params: 134,260,544\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyterlab/conda/envs/python/lib/python3.6/site-packages/ipykernel_launcher.py:4: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "sec_last_base1 = base1.layers[-2].output\n",
    "connected_model1=Dense(len(CLASSES),activation = 'softmax')(sec_last_base1)\n",
    "base1_input = base1.input\n",
    "model_vgg = Model (input = base1_input,output = connected_model1)\n",
    "model_vgg.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vgg.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "STEPS = train_generator.n // train_generator.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "673/673 [==============================] - 1471s 2s/step - loss: 1.5784 - acc: 0.6891 - val_loss: 1.3726 - val_acc: 0.7374\n",
      "Epoch 2/5\n",
      "673/673 [==============================] - 1475s 2s/step - loss: 0.7702 - acc: 0.8270 - val_loss: 1.5491 - val_acc: 0.7430\n",
      "Epoch 3/5\n",
      " 15/673 [..............................] - ETA: 22:10 - loss: 1.0751 - acc: 0.8267"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "N_EPOCHES1 = 5\n",
    "model_vgg.fit_generator(generator=train_generator,\n",
    "                        steps_per_epoch=STEPS, \n",
    "                        epochs=N_EPOCHES1, \n",
    "                        validation_data=validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_history_vgg = model_vgg.history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the loss for both training and validation\n",
    "plt.figure(1)\n",
    "plt.subplot(211)\n",
    "plt.plot(train_history_vgg['loss'])\n",
    "plt.title('Avg Loss vs Epoch')\n",
    "plt.ylabel('avg loss per epoch')\n",
    "plt.xlabel('epoch')\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.plot(train_history_vgg['val_loss'])\n",
    "plt.title('Val Loss vs Epoch')\n",
    "plt.ylabel('val loss per epoch')\n",
    "plt.xlabel('epoch')\n",
    "plt.subplots_adjust(left=None, bottom=0, right=None, top=None, wspace=0, hspace=1)\n",
    "#plt.subplots_adjust(bottom=-1, right=1, top=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "plt.subplot(211)\n",
    "plt.plot(train_history_vgg['acc'])\n",
    "plt.title('Accuracy vs Epoch')\n",
    "plt.ylabel('Accuracy per epoch')\n",
    "plt.xlabel('epoch')\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.plot(train_history_vgg['val_acc'])\n",
    "plt.title('Val acc vs Epoch')\n",
    "plt.ylabel('val acc per epoch')\n",
    "plt.xlabel('epoch')\n",
    "plt.subplots_adjust(left=None, bottom=0, right=None, top=None, wspace=0, hspace=1)\n",
    "#plt.subplots_adjust(bottom=-1, right=1, top=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vgg.save(\"vgg16_keras.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
